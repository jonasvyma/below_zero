{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34a5da1a",
   "metadata": {},
   "source": [
    "# Extracting `HOURLY` data from API and Loading it to DB "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ee8342",
   "metadata": {},
   "source": [
    "As the purpose of our pipeline is to make Weather Data available for comparison to flights and airports data, in the first step we need to load the weather data in a raw form (JSON) into our database. So in later steps we can transform it to meaningful and useful tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad6b31b",
   "metadata": {},
   "source": [
    "### General Presteps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff19378",
   "metadata": {},
   "source": [
    "The Goal of this Notebook is to get raw JSON data for **Hourly** Weather for 3 airport weather stations and load it as it is to our database.\n",
    "- Find Station IDs for **defined** airports (we use the same stations as for the daily data)\n",
    "- Define the start and end of the period\n",
    "- get the API Key from the `.env`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf8dd7e",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a362233",
   "metadata": {},
   "source": [
    "we will need the credentials we saved in the `.env` file. We also will need SQLAlchemy and its functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9602ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will need the credentials we saved in the .env file\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "# We also will need SQLAlchemy and its functions\n",
    "from sqlalchemy import create_engine, types\n",
    "from sqlalchemy.dialects.postgresql import JSON as postgres_json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# requests library will make the API calls. \n",
    "# the json package will parse the JSON string and convert it to Python data structures\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# with 'datetime' we want to catch the timestamp of the API call. For the actuality reference. \n",
    "# and 'time' for slowing down a .bit\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2f4304",
   "metadata": {},
   "source": [
    "### Defining Airports and finding the Station IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead01412",
   "metadata": {},
   "source": [
    "For our Pipeline we will use weather data from the weather stations at the 3 highly frequented airports\n",
    "- **JFK**: John F. Kennedy Airport\n",
    "- **MIA**: Miami International Airport\n",
    "- **LAX**: Los Angeles Airport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e080a0",
   "metadata": {},
   "source": [
    "To find the Station IDs for the airpors without stressing our API Call limits, we will use the   search option of the **https://meteostat.net/**  \n",
    "\n",
    "We can search for the names of the airports above and find the Station IDs.\n",
    "\n",
    "Let's add them to the dictionary below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffa627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_staids = {\n",
    "    'JFK': ???\n",
    "    ,'MIA': ???\n",
    "    ,'LAX': ???\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee31247",
   "metadata": {},
   "source": [
    "### Defining the period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3abdd4f",
   "metadata": {},
   "source": [
    "Our flight Data is from 2024-01-01 until 2024-03-31. For the lectures we will use the same period for the meteostat JSON API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca56ded0",
   "metadata": {},
   "source": [
    "### loading API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting API and DB credentials - Alternative 1: dotenv_values()\n",
    "\n",
    "config = dotenv_values()\n",
    "\n",
    "api_key = config[???] # align the key label with your .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5a6c18",
   "metadata": {},
   "source": [
    "# Part 2: Hourly Station Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c094baa9",
   "metadata": {},
   "source": [
    "During your research of the API you might have noticed that the `Hourly Station API` has an additional restriction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4072dcf9",
   "metadata": {},
   "source": [
    ">#### Hourly data can be queried for a maximum of 30 days per request. \n",
    ">https://dev.meteostat.net/api/stations/hourly.html  \n",
    "> \n",
    ">...actually the notation is not exact, we can still get a full month with 31 days. Nobody is perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce335b1",
   "metadata": {},
   "source": [
    "### Objectives -  Hourly Station Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23714e1f",
   "metadata": {},
   "source": [
    "- create a for-loop for the 3 airports with a nested for-loop for monthly start-, end-dates\n",
    "- eache nested iteration shall generate a **querystring for each API call**\n",
    "- define an empty dictionary to collect: time of the call, airport code, station id, related data\n",
    "- make the API calls using the nested for-loops and fill the dictionary\n",
    "- create pandas dataframe from the dictionary\n",
    "- load the DB credentials from the `.env`\n",
    "- create the engine\n",
    "- define data types for the postgresql table columns\n",
    "- using pandas import the dataframe to the Table in the Schema of the DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a63330",
   "metadata": {},
   "source": [
    "### Generating start & end days per month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06da1da1",
   "metadata": {},
   "source": [
    "We need to create a for-loop iterating over pairs of first and last days of months"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dffd599",
   "metadata": {},
   "source": [
    "Let's say, we want to cover same 3 months of the flights data: **01/01/2024 - 31/03/2024**\n",
    "\n",
    "We can use `pd.date_range()` to get first days in a monthly frequence.  \n",
    "Then using `pd.offsets.MonthEnd()` we get the last days of the month.  \n",
    "Cool thing is, `pd.offsets.MonthEnd()` actually evaluates whether the month is 31, 30, 29 or 28 day long."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424b6958",
   "metadata": {},
   "source": [
    "#### Test: getting the first day of each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c695649",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start='01/01/2024', end='31/03/2024', freq='MS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bdec96",
   "metadata": {},
   "source": [
    "#### Test: getting the last day of a month by adding `+ pd.offsets.MonthEnd()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b640310",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start='01/01/2024', end='31/03/2024', freq='MS') + pd.offsets.MonthEnd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf669d1",
   "metadata": {},
   "source": [
    "#### let's save it in variables..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e21891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_days = pd.date_range(start='01/01/2024', end='31/03/2024', freq='MS')\n",
    "last_days = first_days + pd.offsets.MonthEnd() # see, what we did here? DRY rules! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6080f391",
   "metadata": {},
   "source": [
    "#### ... and make it lists of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a1ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_days_list = first_days.strftime('%Y-%m-%d').tolist()\n",
    "last_days_list = last_days.astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debe5e5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(first_days_list) \n",
    "print(last_days_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb98b276",
   "metadata": {},
   "source": [
    "#### building pairs of (start, end) per month in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35915de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_ranges =[]\n",
    "\n",
    "for start_date, end_date in zip(first_days_list, last_days_list):\n",
    "    monthly_ranges.append((start_date, end_date))\n",
    "\n",
    "monthly_ranges\n",
    "\n",
    "# alternative as list comprehension (less beginner-friendly)\n",
    "# monthly_ranges = [(start_date, end_date) for start_date, end_date in zip(first_days_list, last_days_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d9f355",
   "metadata": {},
   "source": [
    "### Test: `simulating` nested for-loops, creating querystring for each airport for each month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5f2dc7",
   "metadata": {},
   "source": [
    "in order not to overstress the API with too many calls at once, we will use `time.sleep(0.34)` at the end of each loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc64eb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for airport in airport_staids:\n",
    "    print(airport)\n",
    "    \n",
    "    for onemonth in monthly_ranges:\n",
    "    \n",
    "        querystring = {\n",
    "            \"station\":airport_staids[airport]\n",
    "            ,\"start\": ??? # slice the start date from the iterator\n",
    "            ,\"end\": ??? # slice the end date from the iterator\n",
    "            ,\"model\":\"true\"\n",
    "        }\n",
    "         \n",
    "        print(querystrin) \n",
    "       \n",
    "        time.sleep(0.34)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6958d97",
   "metadata": {},
   "source": [
    "How many API calls would that cost per attempt?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c2a12c",
   "metadata": {},
   "source": [
    ">#### If the querystrings look reasonable, we can now run the Hourly Data API calls. Fingers crossed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06070984",
   "metadata": {},
   "source": [
    "### API CALL hourly ( per station) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa373033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  let's catch each response in a dictionary. create an empty dictionary with the following keys:\n",
    "weather_hourly_dict = {'extracted_at':[], \n",
    "                       'airport_code':[], \n",
    "                       'station_id':[], \n",
    "                       'extracted_data':[]}\n",
    "\n",
    "# API CALL hourly (station) - for the syntax: see the rapidapi interface\n",
    "\n",
    "url = \"https://meteostat.p.rapidapi.com/stations/hourly\"\n",
    "\n",
    "headers = {\n",
    "        \"X-RapidAPI-Key\": api_key,\n",
    "        \"X-RapidAPI-Host\": \"meteostat.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "\n",
    "# double for-loop for the querystrings\n",
    "for airport in airport_staids:\n",
    "    \n",
    "    # adding some logs\n",
    "    print(airport) \n",
    "    \n",
    "    for onemonth in monthly_ranges:\n",
    "    \n",
    "        querystring = {\n",
    "            \"station\":airport_staids[airport]\n",
    "            ,\"start\":onemonth[0]\n",
    "            ,\"end\":onemonth[1]\n",
    "            ,\"model\":\"true\"\n",
    "        }\n",
    "        \n",
    "        # making one call with the current querystring\n",
    "        response = requests.get(url, headers=headers, params=querystring)\n",
    "        \n",
    "        # adding some logs to catch errors\n",
    "        if response.status_code != 200:\n",
    "            print(f'status code {response.status_code} -> research error')\n",
    "            print(querystring, end=\"\\n\\n\")\n",
    "        else:\n",
    "            print(querystring)\n",
    "        \n",
    "        # appending data to the dictionary:\n",
    "        weather_hourly_dict['extracted_at'].append(datetime.now())                # timestamp,\n",
    "        weather_hourly_dict['airport_code'].append(airport)                       # airport code\n",
    "        weather_hourly_dict['station_id'].append(airport_staids[airport])         # weater Station ID\n",
    "        weather_hourly_dict['extracted_data'].append(json.loads(response.text))   # JSON string\n",
    "        \n",
    "        time.sleep(0.34)\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86625015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the dictionary\n",
    "weather_hourly_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c0091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe\n",
    "\n",
    "weather_hourly_df = pd.DataFrame(weather_hourly_dict)\n",
    "weather_hourly_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9060b68",
   "metadata": {},
   "source": [
    "### SIDEBAR: For the curious and sceptics..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9c13fb",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "    In case you can't resist to know what the data looks like when flattened. \n",
    "    Here is the preview with pandas. BUT we are not transforming before loading in our pipeline just yet. \n",
    "    We Extract and Load the raw JSON."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f495ac43",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# using pd.json_normalize() twice to get to the hourly weather_stats of an airport in a particular month under 'data'\n",
    "\n",
    "df_JFK_jan24 = pd.json_normalize(pd.json_normalize(weather_hourly_df['extracted_data']).loc[0, 'data'])\n",
    "df_JFK_jan24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93a11f1",
   "metadata": {},
   "source": [
    "> #### Note: we only used up 9 more API calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffc68de",
   "metadata": {},
   "source": [
    "### Loading the data into the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884171f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting API and DB credentials - Alternative 1: dotenv_values()\n",
    "\n",
    "config = dotenv_values()\n",
    " \n",
    "pg_user = config['POSTGRES_USER'] # align the key labels with your .env file\n",
    "pg_host = config['POSTGRES_HOST']\n",
    "pg_port = config['POSTGRES_PORT']\n",
    "pg_db = config['POSTGRES_DB']\n",
    "pg_schema = config['POSTGRES_SCHEMA']\n",
    "pg_pass = config['POSTGRES_PASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f2fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating the url\n",
    "url = f'postgresql://{pg_user}:{pg_pass}@{pg_host}:{pg_port}/{pg_db}'\n",
    "\n",
    "# creating the engine\n",
    "engine = create_engine(url, echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8540ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.url # checking the url (pass is hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f26f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining data types for the DB\n",
    "dtype_dict = {\n",
    "    'extracted_at':types.DateTime,\n",
    "    'airport_code': types.String,\n",
    "    'station_id': types.Integer,\n",
    "    'extracted_data':postgres_json\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a50976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing dataframe to DB\n",
    "weather_hourly_df.to_sql(name = 'weather_hourly_raw', \n",
    "                       con = engine, \n",
    "                       schema = pg_schema, \n",
    "                       if_exists='replace', \n",
    "                       dtype=dtype_dict,\n",
    "                       index=False\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c758d3d",
   "metadata": {},
   "source": [
    "The result of the last cell should give you the number of rows you imported to the DB table `weather_hourly_raw`. Each row contains data from one API call.\n",
    "\n",
    "Check in DBeaver if you see a new table in your Schema. Don't forget to refresh your Schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6017fd10",
   "metadata": {},
   "source": [
    "## Done. We finished \"Loading\"! :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
